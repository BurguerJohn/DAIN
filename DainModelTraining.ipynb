{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Dain Model Training.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1vOW77SzuW0CF9lUj3W57GhqxbYSRJHoF","authorship_tag":"ABX9TyMWZ/RwXVc7gE/5V5GTkjTT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"cWpo9q7lkR8X","colab_type":"text"},"source":["# Check what processor Colab made avaiable to you:"]},{"cell_type":"code","metadata":{"id":"IabsZDECZCDg","colab_type":"code","colab":{}},"source":["import torch\n","torch.cuda.get_device_name(0)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RqA5RLmRkdRN","colab_type":"text"},"source":["# Clone the project"]},{"cell_type":"code","metadata":{"id":"xEobV2KCMX3H","colab_type":"code","colab":{}},"source":["!git clone https://github.com/BurguerJohn/DAIN"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"riIpSmo0khQA","colab_type":"text"},"source":["# Install requirements"]},{"cell_type":"code","metadata":{"id":"yc2SKi9_MpRl","colab_type":"code","colab":{}},"source":["!pip install torch==1.3.1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X3oGTvv6ScrE","colab_type":"code","colab":{}},"source":["!pip install scipy==1.1.0"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tBWM7qAOkrbJ","colab_type":"text"},"source":["# Build Scripts\n","This can take between 5 and 20 minutes."]},{"cell_type":"code","metadata":{"id":"URLAK9tpMrnD","colab_type":"code","colab":{}},"source":["%%bash\n","cd /content/DAIN/my_package\n","sh build.sh"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1rZ-ffN2Mr-v","colab_type":"code","colab":{}},"source":["%%bash\n","cd /content/DAIN/PWCNet/correlation_package_pytorch1_0\n","sh build.sh"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qFXxCdA7kvKn","colab_type":"text"},"source":["#Required models Download"]},{"cell_type":"code","metadata":{"id":"McokF-jKNJvD","colab_type":"code","colab":{}},"source":["!mkdir /content/DAIN/MegaDepth/checkpoints/\n","!mkdir /content/DAIN/MegaDepth/checkpoints/test_local\n","%cd /content/DAIN/MegaDepth/checkpoints/test_local\n","!wget http://vllab1.ucmerced.edu/~wenbobao/DAIN/best_generalization_net_G.pth\n","%cd /content/DAIN/PWCNet\n","!wget http://vllab1.ucmerced.edu/~wenbobao/DAIN/pwc_net.pth.tar"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0MQPFJVUk8vN","colab_type":"text"},"source":["# Optional model Download.\n","This is the model used in Dain-App, only download it if you want to keep training on top of the existing model"]},{"cell_type":"code","metadata":{"id":"TcoUK6eUlG5q","colab_type":"code","colab":{}},"source":["%cd /content/\n","!wget http://vllab1.ucmerced.edu/~wenbobao/DAIN/best.pth"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ckjVBAKGlMWB","colab_type":"text"},"source":["# Tool to generate a DataSet\n","Put all your videos on a folder and run this script to generate triplets [3 PNG's sequence] from all the videos inside that folder."]},{"cell_type":"code","metadata":{"id":"FzQKHeejjjNL","colab_type":"code","colab":{}},"source":["#@markdown Folder path with all the videos\n","inputPath = \"/content/input/\" #@param{type:\"string\"}\n","#@markdown Path to generate the Database\n","outputPath = \"/content/dataset_01/\" #@param{type:\"string\"}\n","#@markdown The bigger the value, the more alike the frames need to be to be considered a triplet.\n","psnr = 25 #@param{type:\"number\"}\n","#@markdown The original model was trained with images of res 448X256, this bool turn all frames to that resolution.\n","resize = True #@param{type:\"boolean\"}\n","\n","#Original dataset information:\n","#Vimeo-90K triplets dataset contains 91701 triplets extracted from 15k video clips.\n","#Each triplet is a short RGB video sequence that consists of 3 frames with fixed resolution 448x256\n","\n","\n","def calculate_psnr(img1, img2, max_value=255):\n","    \"\"\"\"Calculating peak signal-to-noise ratio (PSNR) between two images.\"\"\"\n","    i1 = PIL.Image.open(img1).convert('RGB')\n","    i2 = PIL.Image.open(img2).convert('RGB')\n","\n","    mse = np.mean((np.array(i1, dtype=np.float32) - np.array(i2, dtype=np.float32)) ** 2)\n","    if mse == 0:\n","        return 100\n","    return 20 * np.log10(max_value / (np.sqrt(mse)))\n","\n","\n","def IsDiffScenes(img1, img2, diff=25):\n","  return calculate_psnr(img1, img2) <= diff\n","\n","\n","import os\n","import shutil\n","from shutil import copyfile\n","import time\n","import PIL\n","import numpy as np\n","\n","\n","if not os.path.isdir(outputPath):\n","  os.makedirs(outputPath)\n","\n","if not os.path.isdir(outputPath + \"sequences\"):\n","  os.makedirs(outputPath + \"sequences\")\n","\n","counter = 1\n","for video in sorted(os.listdir(inputPath)):\n","  temp = \"/content/.temp/\"\n","  path = inputPath + video\n","  if os.path.isdir(temp):\n","    shutil.rmtree(temp)\n","    #time.sleep(2)\n","  os.makedirs(temp)\n","\n","  rescale = \"\"\n","  if resize:\n","    rescale=\"scale=448:-1,pad=ceil(iw/2)*2:256,\"\n","  !ffmpeg -i \"{path}\" -vf \"{rescale}mpdecimate\" -vsync 0 -qscale:v 1 -pix_fmt rgb24  \"{temp}%10d.png\"\n","\n","  root =outputPath + \"/sequences/\" + str(counter).zfill(3) + \"/\"\n","  if not os.path.isdir(root):\n","    os.makedirs(root)\n","\n","\n","  triIndex = 1\n","  images = sorted(os.listdir(temp))\n","  for i in range(2, len(images)) :\n","    im1 = temp + images[i-2]\n","    im2 =  temp + images[i-1]\n","    im3 =  temp + images[i]\n","    if IsDiffScenes(im1, im2, psnr) == False and IsDiffScenes(im2, im3, psnr) == False:\n","      #print(\"Triplet Found\")\n","      triPath = root + str(triIndex).zfill(5) + \"/\"\n","      if not os.path.isdir(triPath):\n","        os.makedirs(triPath)\n","      copyfile(im1, triPath + \"im1.png\")\n","      copyfile(im2, triPath + \"im2.png\")\n","      copyfile(im3, triPath + \"im3.png\")\n","      triIndex +=1\n","\n","  counter += 1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-PlUuP6gm3e2","colab_type":"text"},"source":["# Tool to generate the training and testing set of a DataSet"]},{"cell_type":"code","metadata":{"id":"ANe6jAWdpy9B","colab_type":"code","colab":{}},"source":["#@markdown The folder path of the generated Dataset\n","database = \"/content/dataset_01/\" #@param{type:\"string\"}\n","#@markdown Percentage of frames that will be to the testing group.\n","testingPercentage = 0.2 #@param{type:\"slider\", min:0.1, max:0.9, step:0.1}\n","\n","import random\n","\n","if os.path.isfile(database + \"tri_testlist.txt\"):\n","  os.remove(database + \"tri_testlist.txt\")\n","if os.path.isfile(database + \"tri_trainlist.txt\"):\n","  os.remove(database + \"tri_trainlist.txt\")\n","\n","from glob import glob\n","folders = glob(database + \"sequences/*/\")\n","\n","paths = []\n","\n","for i in range(0, len(folders)):\n","  triplets = glob(folders[i] + \"/*/\")\n","  for ii in range(0, len(triplets)):\n","    innerF = os.path.basename((os.path.dirname(triplets[ii])))\n","    outF = os.path.basename((os.path.dirname(folders[i])))\n","    paths.append(outF + \"/\" + innerF)\n","\n","def partitionRankings(rawRatings, testPercent):\n","    howManyNumbers = int(round(testPercent*len(rawRatings)))\n","    shuffled = rawRatings[:]\n","    random.shuffle(shuffled)\n","    return shuffled[howManyNumbers:], shuffled[:howManyNumbers]\n","\n","training, test = partitionRankings(paths, testingPercentage)\n","\n","\n","trainTxt = database + \"/tri_trainlist.txt\"\n","trainFile = open(trainTxt, 'w')\n","\n","testTxt = database + \"/tri_testlist.txt\"\n","testFile = open(testTxt, 'w')\n","\n","for txt in training:\n","  trainFile.write(txt + \"\\n\")\n","trainFile.close()\n","\n","for txt in test:\n","  testFile.write(txt + \"\\n\")\n","testFile.close()\n","\n","print(training)\n","print(test)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZW8oBuAOnocP","colab_type":"text"},"source":["# Train the model (This take a long time)"]},{"cell_type":"code","metadata":{"id":"ksy78n0mNnW5","colab_type":"code","colab":{}},"source":["%cd /content/DAIN\n","#@markdown Folder Path with the database\n","datapath_set = \"/content/dataset_01\" #@param{type:\"string\"}\n","#@markdown Empty if you want to start a new model from scratch.\n","#@markdown Set the path for the older model if you want to keep training it.\n","model_weigh = \"\" #@param{type:\"string\"}\n","#@markdown Size of the batch\n","batch_size = 3 #@param{type:\"number\"}\n","\n","!CUDA_VISIBLE_DEVICES=0 python -W ignore train.py --datasetPath \"{datapath_set}\" --SAVED_MODEL \"{model_weigh}\" --batch_size {batch_size} --save_which 1 --lr 0.0005 --rectify_lr 0.0005 --flow_lr_coe 0.01 --occ_lr_coe 0.0 --filter_lr_coe 1.0 --ctx_lr_coe 1.0 --alpha 0.0 1.0 --patience 4 --factor 0.2"],"execution_count":0,"outputs":[]}]}